{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sys.path.append(os.path.join(os.path.abspath(os.path.join('../..')), 'src'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy\n",
    "import scipy\n",
    "import pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import mysql_utils\n",
    "import doc_proc\n",
    "import init_tdm_tables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Init Needed Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dd = lambda doc: doc_proc.build_text_feature(doc, \n",
    "                                                 components = ['title', 'summary'],\n",
    "                                                 lower=False, \n",
    "                                                 remove_stops=False,\n",
    "                                                 html_text=True,\n",
    "                                                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dp = init_tdm_tables.DocProcessor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cnx = mysql_utils.getCnx()\n",
    "cur = mysql_utils.getCur(cnx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def query_wordIDLookup(cur, words):\n",
    "    format_strings = ','.join([\"%s\"] * len(words))\n",
    "    query = (\"SELECT id, word FROM words \"\n",
    "             \"WHERE word IN ({})\".format(format_strings))\n",
    "    cur.execute(query, list(words))\n",
    "    cols = cur.column_names\n",
    "    word_lookup = [{cols[0] : e[0], cols[1] : e[1]} for e in cur.fetchall()]\n",
    "    word_lookup = {e['id'] : e['word'] for e in word_lookup}\n",
    "    return(word_lookup)\n",
    "\n",
    "\n",
    "def query_idWordLookup(cur, wids):\n",
    "    format_strings = ','.join([\"%s\"] * len(wids))\n",
    "    query = (\"SELECT id, word FROM words \"\n",
    "             \"WHERE id IN ({})\".format(format_strings))\n",
    "    cur.execute(query, list(wids))\n",
    "    cols = cur.column_names\n",
    "    word_lookup = [{cols[0] : e[0], cols[1] : e[1]} for e in cur.fetchall()]\n",
    "    word_lookup = {e['id'] : e['word'] for e in word_lookup}\n",
    "    return(word_lookup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "stops_lookup = query_wordIDLookup(cur, doc_proc.nltk_stops)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Query Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "doc = {\"title\" : \"FBI refused White House request to knock down recent Trump-Russia stories\",\n",
    "       \"summary\" : \"Washington (CNN) The FBI rejected a recent White House request to publicly knock down media reports about communications between Donald Trump's associates and Russians known to US intelligence during the 2016 presidential campaign, multiple US officials briefed on the matter tell CNN.\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bow = dp.doc2BOW(dd(doc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "query_words = [w for w in bow if w not in doc_proc.nltk_stops]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Query for Docs that Share Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def query_docsOnWords(cur, words, word_type=\"word\", exclude_docs=set()):\n",
    "    \n",
    "    if word_type == \"word\":\n",
    "        word_doc_query = (\"SELECT doc_bows.doc_id, doc_bows.wcount \"\n",
    "                          \"FROM  doc_bows LEFT JOIN words ON (doc_bows.word_id = words.id) \"\n",
    "                          \"WHERE words.word = '{}'\")\n",
    "    elif word_type == \"id\":\n",
    "        word_doc_query = (\"SELECT doc_bows.doc_id, doc_bows.wcount \"\n",
    "                          \"FROM  doc_bows LEFT JOIN words ON (doc_bows.word_id = words.id) \"\n",
    "                          \"WHERE words.id = '{}'\")\n",
    "\n",
    "    doc_ids = set()\n",
    "    word_count_store = []\n",
    "    for word in words:\n",
    "        cur.execute(word_doc_query.format(word))\n",
    "        result = mysql_utils.dfDocsFromCursor(cur)\n",
    "        result = result[[i not in exclude_docs for i in result['doc_id']]]\n",
    "        if result.shape[0] > 0:\n",
    "            doc_ids.update(set(result['doc_id']))\n",
    "            word_count_store.append({'word' : word,\n",
    "                                     'n_docs' : result.shape[0],\n",
    "                                     'n_tot' : result['wcount'].sum()})\n",
    "\n",
    "    doc_ids = [int(i) for i in doc_ids]\n",
    "    word_count_store = pandas.DataFrame(word_count_store)\n",
    "        \n",
    "    return(doc_ids, word_count_store)\n",
    "\n",
    "\n",
    "def word_summary_info(cur, words, wtype='id', exclude_docs=set()):\n",
    "    \n",
    "    if exclude_docs:\n",
    "        exclude_docs = [str(int(did)) for did in exclude_docs]\n",
    "        exclude_docs = \", \".join(exclude_docs)\n",
    "        exclude_where_text = \"AND doc_bows.doc_id NOT IN ({}) \".format(exclude_docs)\n",
    "        \n",
    "    format_strings = ', '.join(['%s'] * len(words))\n",
    "    \n",
    "    if wtype=='word':\n",
    "        where_clause = \"WHERE words.word IN ({}) \".format(format_strings)\n",
    "        if exclude_docs:\n",
    "            where_clause += exclude_where_text\n",
    "        query = \"SELECT doc_bows.word_id, COUNT(doc_bows.doc_id) as n_docs, SUM(doc_bows.wcount) as n_total \" +\\\n",
    "                 \"FROM  doc_bows LEFT JOIN words ON (doc_bows.word_id = words.id) \" +\\\n",
    "                 where_clause +\\\n",
    "                 \"GROUP BY doc_bows.word_id\"\n",
    "        \n",
    "    elif wtype=='id':\n",
    "        where_clause = \"WHERE doc_bows.word_id IN ({}) \".format(format_strings)\n",
    "        if exclude_docs:\n",
    "            where_clause += exclude_where_text\n",
    "        query = \"SELECT doc_bows.word_id, COUNT(doc_bows.doc_id) as n_docs, SUM(doc_bows.wcount) as n_total \" +\\\n",
    "                 \"FROM  doc_bows \" +\\\n",
    "                 where_clause +\\\n",
    "                 \"GROUP BY doc_bows.word_id\"\n",
    "            \n",
    "    cur.execute(query, (words))\n",
    "    result = mysql_utils.dfDocsFromCursor(cur)\n",
    "    return(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Orig Doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "word_count_info = word_summary_info(cur, query_words, wtype='word')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count      31.000000\n",
       "mean      723.741935\n",
       "std      1476.303152\n",
       "min        10.000000\n",
       "25%        61.500000\n",
       "50%       233.000000\n",
       "75%       705.500000\n",
       "max      7586.000000\n",
       "Name: n_docs, dtype: float64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_count_info.n_docs.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Arbit...this should be \"decayed\"....see below\n",
    "ndoc_cutoff = 100\n",
    "\n",
    "qw_l01 = [int(w) for w in list(word_count_info[word_count_info.n_docs < ndoc_cutoff].word_id)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 2nd Pass: Get Doc IDs to use\n",
    "docs_l01, wcs_l01 = query_docsOnWords(cur, qw_l01, word_type='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2294, 2900, 2901, 3072, 4148, 5427, 6202, 6327, 12578, 27973]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qw_l01"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Level 1 Documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def query_docBOW(cur, doc_id, word_list = []):\n",
    "    query = \"SELECT word_id, wcount FROM doc_bows WHERE doc_id = {}\".format(doc_id)\n",
    "    cur.execute(query)\n",
    "    cols = cur.column_names\n",
    "    bow = [{cols[0] : e[0], cols[1] : e[1]} for e in cur.fetchall()]\n",
    "    if word_list:\n",
    "        bow = [e for e in bow if e['word_id'] in word_list]\n",
    "    return(bow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def query_AllDocWords(cur, doc_ids):\n",
    "    doc_ids = list(doc_ids)\n",
    "    format_strings = ','.join(['%s'] * len(doc_ids))\n",
    "    query = (\"SELECT DISTINCT word_id \"\n",
    "             \"FROM doc_bows \"\n",
    "             \"WHERE doc_id IN ({})\".format(format_strings))\n",
    "    cur.execute(query, (doc_ids))\n",
    "    words = [e[0] for e in cur.fetchall()]\n",
    "    return(words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This stepo is a bottleneck; can i pre-reduce the query words by using info from the sub-set?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Have the word stats for all words queued up already.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "query_words = query_AllDocWords(cur, docs_l01)\n",
    "query_words = [w for w in query_words if w not in stops_lookup.keys()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "word_count_info = word_summary_info(cur, query_words, wtype='id', exclude_docs=docs_l01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    3786.000000\n",
       "mean      110.771527\n",
       "std       247.038269\n",
       "min         1.000000\n",
       "25%        13.000000\n",
       "50%        45.000000\n",
       "75%       123.750000\n",
       "max      7506.000000\n",
       "Name: n_docs, dtype: float64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_count_info.n_docs.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ndoc_cutoff_l2 = 15\n",
    "qw_l02 = [int(w) for w in list(word_count_info[word_count_info.n_docs < ndoc_cutoff_l2].word_id)]\n",
    "docs_l02, wcs_l02 = query_docsOnWords(cur, qw_l02,\n",
    "                                      word_type=\"id\", exclude_docs=docs_l01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5141"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(docs_l02)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "qww = query_idWordLookup(cur, qw_l02)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "surgeon\n",
      "tales\n",
      "bureau\n",
      "barker\n",
      "directed\n",
      "jacob\n",
      "masked\n",
      "afp\n",
      "headscarf\n",
      "mufti\n"
     ]
    }
   ],
   "source": [
    "for i in qw_l02[:10]:\n",
    "    print(qww[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Network from Selected Vocab, Docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "words = set(qw_l01).copy()\n",
    "words.update(qw_l02)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bows = {}\n",
    "for d in docs_l01:\n",
    "    bows[d] = query_docBOW(cur, d, word_list=words)\n",
    "for d in docs_l02:\n",
    "    bows[d] = query_docBOW(cur, d, word_list=words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cnx.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rss (P3)",
   "language": "python",
   "name": "rss_p3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
